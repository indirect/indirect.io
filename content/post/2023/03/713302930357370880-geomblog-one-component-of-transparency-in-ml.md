+++
aliases = ["/post/713302930357370880/geomblog-one-component-of-transparency-in-ml"]
date = 2023-03-31T10:31:24Z
id = "713302930357370880"
slug = "geomblog-one-component-of-transparency-in-ml"
type = "tumblr-text"

[tumblr]
interactability_blaze = "everyone"
is_blocks_post_format = false
blog_name = "indirect"
is_blaze_pending = false
slug = "geomblog-one-component-of-transparency-in-ml"
format = "html"
post_url = "https://indirect.io/post/713302930357370880/geomblog-one-component-of-transparency-in-ml"
can_reply = false
is_blazed = false
can_send_in_message = true
can_like = false
id_string = "713302930357370880"
reblog_key = "0fbv1kXs"
short_url = "https://tmblr.co/ZY3jbydcAJnbCa00"
display_avatar = true
should_open_in_legacy = false
note_count = 0.0
state = "published"
type = "text"
id = 7.133029303573709e+17
timestamp = 1680258684.0
can_reblog = false
body = "<blockquote><p>\n<a href=\"http://twitter.com/geomblog/status/1637557756549799936\">@geomblog</a>: One component of transparency in ML oversight is: &ldquo;what data was the model trained on&rdquo;. It seems like this would be impossible to answer for LLMs, (and might very well be), but the fascinating thread below shows why the answer to this question is important: 1/n\n</p></blockquote>\n\nIn Silicon Valley culture, the groupthink seems to be that it&rsquo;s impossible to keep track of the data a language model is trained on, yet it *is* possible to solve artificial general intelligence. This requires a reality distortion that blends myopia with narcissism. — <a href=\"http://twitter.com/mmitchell_ai/status/1637573202070364161\">@mmitchell_ai</a>"
can_blaze = false
date = "2023-03-31 10:31:24 GMT"
summary = "@geomblog: One component of transparency in ML oversight is: \"what data was the model trained on\". It seems like this would be..."
interactability_reblog = "everyone"

[[tumblr.trail]]
content_raw = "<p><blockquote><p>\n<a href=\"http://twitter.com/geomblog/status/1637557756549799936\">@geomblog</a>: One component of transparency in ML oversight is: “what data was the model trained on”. It seems like this would be impossible to answer for LLMs, (and might very well be), but the fascinating thread below shows why the answer to this question is important: 1/n\n</p></blockquote>\n\nIn Silicon Valley culture, the groupthink seems to be that it’s impossible to keep track of the data a language model is trained on, yet it *is* possible to solve artificial general intelligence. This requires a reality distortion that blends myopia with narcissism. — <a href=\"http://twitter.com/mmitchell_ai/status/1637573202070364161\">@mmitchell_ai</a></p>"
content = "<p><blockquote><p>\n<a href=\"http://twitter.com/geomblog/status/1637557756549799936\">@geomblog</a>: One component of transparency in ML oversight is: &ldquo;what data was the model trained on&rdquo;. It seems like this would be impossible to answer for LLMs, (and might very well be), but the fascinating thread below shows why the answer to this question is important: 1/n\n</p></blockquote>\n\nIn Silicon Valley culture, the groupthink seems to be that it&rsquo;s impossible to keep track of the data a language model is trained on, yet it *is* possible to solve artificial general intelligence. This requires a reality distortion that blends myopia with narcissism. &mdash; <a href=\"http://twitter.com/mmitchell_ai/status/1637573202070364161\">@mmitchell_ai</a></p>"
is_current_item = true
is_root_item = true

[tumblr.trail.blog]
name = "indirect"
active = true
share_likes = false
share_following = false
can_be_followed = true

[tumblr.trail.blog.theme]
header_full_width = 3000.0
title_color = "#444444"
title_font = "Gibson"
header_full_height = 1055.0
header_bounds = ""
header_image = "/images/3d/b4/6d99210450f4a662c36d5f619a3b.png"
header_image_focused = "/images/59/17/48d16ee01f6d456797714a5e291b.png"
show_title = true
avatar_shape = "square"
body_font = "Helvetica Neue"
header_image_scaled = "/images/59/17/48d16ee01f6d456797714a5e291b.png"
show_description = true
show_header_image = false
title_font_weight = "bold"
background_color = "#FAFAFA"
header_image_poster = ""
header_stretch = true
link_color = "#529ECC"
show_avatar = true

[tumblr.trail.post]
id = "713302930357370880"

[tumblr.reblog]
comment = "<p><blockquote><p>\n<a href=\"http://twitter.com/geomblog/status/1637557756549799936\">@geomblog</a>: One component of transparency in ML oversight is: “what data was the model trained on”. It seems like this would be impossible to answer for LLMs, (and might very well be), but the fascinating thread below shows why the answer to this question is important: 1/n\n</p></blockquote>\n\nIn Silicon Valley culture, the groupthink seems to be that it’s impossible to keep track of the data a language model is trained on, yet it *is* possible to solve artificial general intelligence. This requires a reality distortion that blends myopia with narcissism. — <a href=\"http://twitter.com/mmitchell_ai/status/1637573202070364161\">@mmitchell_ai</a></p>"
tree_html = ""

[tumblr.blog]
description = ""
url = "https://indirect.io/"
uuid = "t:PgyUJU3SA2Klwyt81UWAwQ"
updated = 1739927643.0
can_show_badges = false
name = "indirect"
title = "indirect"

[tumblr.blog.tumblrmart_accessories]
+++
