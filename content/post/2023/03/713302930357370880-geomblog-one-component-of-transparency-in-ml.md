+++
aliases = ["/post/713302930357370880/geomblog-one-component-of-transparency-in-ml"]
date = 2023-03-31T10:31:24Z
id = "713302930357370880"
slug = "geomblog-one-component-of-transparency-in-ml"
type = "tumblr-text"

[tumblr]
type = "text"
blog_name = "indirect"
state = "published"
is_blocks_post_format = false
display_avatar = true
id = 7.133029303573709e+17
id_string = "713302930357370880"
summary = "@geomblog: One component of transparency in ML oversight is: \"what data was the model trained on\". It seems like this would be..."
body = "<blockquote><p>\n<a href=\"http://twitter.com/geomblog/status/1637557756549799936\">@geomblog</a>: One component of transparency in ML oversight is: &ldquo;what data was the model trained on&rdquo;. It seems like this would be impossible to answer for LLMs, (and might very well be), but the fascinating thread below shows why the answer to this question is important: 1/n\n</p></blockquote>\n\nIn Silicon Valley culture, the groupthink seems to be that it&rsquo;s impossible to keep track of the data a language model is trained on, yet it *is* possible to solve artificial general intelligence. This requires a reality distortion that blends myopia with narcissism. — <a href=\"http://twitter.com/mmitchell_ai/status/1637573202070364161\">@mmitchell_ai</a>"
timestamp = 1680258684.0
format = "html"
reblog_key = "0fbv1kXs"
should_open_in_legacy = false
can_reblog = false
post_url = "https://indirect.io/post/713302930357370880/geomblog-one-component-of-transparency-in-ml"
can_like = false
is_blazed = false
is_blaze_pending = false
slug = "geomblog-one-component-of-transparency-in-ml"
date = "2023-03-31 10:31:24 GMT"
short_url = "https://tmblr.co/ZY3jbydcAJnbCa00"
note_count = 0.0
interactability_blaze = "everyone"
can_send_in_message = true
can_blaze = false
interactability_reblog = "everyone"
can_reply = false

[tumblr.reblog]
tree_html = ""
comment = "<p><blockquote><p>\n<a href=\"http://twitter.com/geomblog/status/1637557756549799936\">@geomblog</a>: One component of transparency in ML oversight is: “what data was the model trained on”. It seems like this would be impossible to answer for LLMs, (and might very well be), but the fascinating thread below shows why the answer to this question is important: 1/n\n</p></blockquote>\n\nIn Silicon Valley culture, the groupthink seems to be that it’s impossible to keep track of the data a language model is trained on, yet it *is* possible to solve artificial general intelligence. This requires a reality distortion that blends myopia with narcissism. — <a href=\"http://twitter.com/mmitchell_ai/status/1637573202070364161\">@mmitchell_ai</a></p>"

[tumblr.blog]
updated = 1739939727.0
can_show_badges = false
name = "indirect"
title = "indirect"
description = ""
url = "https://indirect.io/"
uuid = "t:PgyUJU3SA2Klwyt81UWAwQ"

[tumblr.blog.tumblrmart_accessories]

[[tumblr.trail]]
content_raw = "<p><blockquote><p>\n<a href=\"http://twitter.com/geomblog/status/1637557756549799936\">@geomblog</a>: One component of transparency in ML oversight is: “what data was the model trained on”. It seems like this would be impossible to answer for LLMs, (and might very well be), but the fascinating thread below shows why the answer to this question is important: 1/n\n</p></blockquote>\n\nIn Silicon Valley culture, the groupthink seems to be that it’s impossible to keep track of the data a language model is trained on, yet it *is* possible to solve artificial general intelligence. This requires a reality distortion that blends myopia with narcissism. — <a href=\"http://twitter.com/mmitchell_ai/status/1637573202070364161\">@mmitchell_ai</a></p>"
content = "<p><blockquote><p>\n<a href=\"http://twitter.com/geomblog/status/1637557756549799936\">@geomblog</a>: One component of transparency in ML oversight is: &ldquo;what data was the model trained on&rdquo;. It seems like this would be impossible to answer for LLMs, (and might very well be), but the fascinating thread below shows why the answer to this question is important: 1/n\n</p></blockquote>\n\nIn Silicon Valley culture, the groupthink seems to be that it&rsquo;s impossible to keep track of the data a language model is trained on, yet it *is* possible to solve artificial general intelligence. This requires a reality distortion that blends myopia with narcissism. &mdash; <a href=\"http://twitter.com/mmitchell_ai/status/1637573202070364161\">@mmitchell_ai</a></p>"
is_current_item = true
is_root_item = true

[tumblr.trail.blog]
share_likes = false
share_following = false
can_be_followed = true
name = "indirect"
active = true

[tumblr.trail.blog.theme]
avatar_shape = "square"
body_font = "Helvetica Neue"
header_image_scaled = "/images/59/17/48d16ee01f6d456797714a5e291b.png"
show_header_image = false
title_font_weight = "bold"
header_image_focused = "/images/59/17/48d16ee01f6d456797714a5e291b.png"
show_avatar = true
show_title = true
title_font = "Gibson"
show_description = true
header_full_width = 3000.0
background_color = "#FAFAFA"
header_bounds = ""
header_image = "/images/3d/b4/6d99210450f4a662c36d5f619a3b.png"
header_image_poster = ""
title_color = "#444444"
header_full_height = 1055.0
link_color = "#529ECC"
header_stretch = true

[tumblr.trail.post]
id = "713302930357370880"
+++
